import numpy as np
from scipy import signal
from scipy.interpolate import interp1d

class FemaleGaitAnalyzer:
    def __init__(self):
        # è‡¨åºŠçš„ãªé–¾å€¤ï¼ˆSakane 2025ãƒ¢ãƒ‡ãƒ«æº–æ‹ ï¼‰
        self.thresholds = {
            'knee_extension_ideal': 175.0,
            'knee_extension_good': 170.0,
            'knee_extension_minimum': 165.0,
            'stance_phase_mean_minimum': 168.0,
            'trunk_alignment_ideal': 5.0,
            'trunk_risk_threshold': 15.0,
            # ä¸€è²«æ€§è©•ä¾¡ã®æ–°ã—ã„é–¾å€¤
            'consistency_excellent': 3.0,
            'consistency_good': 5.0,
            'consistency_moderate': 10.0,
            'consistency_poor': 15.0,
        }
        
        # æ­©è¡Œå‘¨æœŸæ¤œå‡ºã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.gait_cycle_params = {
            'min_peak_distance': 15,
            'prominence': 5.0,
        }
        
        # ä¿¡é ¼åº¦ãƒ•ã‚£ãƒ«ã‚¿ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.confidence_params = {
            'min_visibility': 0.7,
            'max_angle_change': 8.0,
            'noise_window': 5,
            # è§£å‰–å­¦çš„åˆ¶é™
            'min_anatomical_angle': 90.0,
            'max_anatomical_angle': 185.0,
        }

    def _calculate_angle(self, a, b, c):
        """3ç‚¹ã®åº§æ¨™ã‹ã‚‰è§’åº¦ã‚’è¨ˆç®—ï¼ˆ180åº¦ã‚’æœ€å¤§ã¨ã™ã‚‹ï¼‰"""
        a, b, c = np.array(a), np.array(b), np.array(c)
        ba, bc = a - b, c - b
        cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))
        return np.degrees(np.arccos(np.clip(cosine_angle, -1.0, 1.0)))

    def _apply_anatomical_constraints(self, angles):
        """è§£å‰–å­¦çš„ã«å¦¥å½“ãªç¯„å›²ã«è§’åº¦ã‚’åˆ¶é™"""
        angles = np.array(angles)
        min_angle = self.confidence_params['min_anatomical_angle']
        max_angle = self.confidence_params['max_anatomical_angle']
        
        invalid_mask = (angles < min_angle) | (angles > max_angle)
        
        if not np.any(invalid_mask):
            return angles
        
        valid_indices = np.where(~invalid_mask)[0]
        
        if len(valid_indices) < 2:
            median_val = np.median(angles[~invalid_mask]) if np.any(~invalid_mask) else 170.0
            angles[invalid_mask] = median_val
            return angles
        
        interp_func = interp1d(
            valid_indices,
            angles[valid_indices],
            kind='linear',
            fill_value='extrapolate'
        )
        
        invalid_indices = np.where(invalid_mask)[0]
        angles[invalid_indices] = interp_func(invalid_indices)
        angles = np.clip(angles, min_angle, max_angle)
        
        return angles

    def _filter_by_confidence(self, angles, visibilities):
        """ä¿¡é ¼åº¦ãƒ•ã‚£ãƒ«ã‚¿ï¼šä½ä¿¡é ¼åº¦ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è£œå®Œãƒ»é™¤å¤–"""
        if len(angles) != len(visibilities):
            return np.array(angles)
        
        angles = np.array(angles)
        visibilities = np.array(visibilities)
        
        # è§£å‰–å­¦çš„åˆ¶ç´„ã‚’é©ç”¨
        angles = self._apply_anatomical_constraints(angles)
        
        # ä½ä¿¡é ¼åº¦ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒã‚¹ã‚¯
        valid_mask = visibilities >= self.confidence_params['min_visibility']
        
        if np.sum(valid_mask) < 10:
            return angles
        
        # ç·šå½¢è£œé–“ã§ä½ä¿¡é ¼åº¦ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åŸ‹ã‚ã‚‹
        valid_indices = np.where(valid_mask)[0]
        if len(valid_indices) < len(angles):
            interp_func = interp1d(
                valid_indices, 
                angles[valid_mask], 
                kind='linear', 
                fill_value='extrapolate'
            )
            all_indices = np.arange(len(angles))
            angles = interp_func(all_indices)
        
        # æ€¥æ¿€ãªå¤‰åŒ–ã‚’æ¤œå‡ºã—ã¦å¹³æ»‘åŒ–
        angle_diffs = np.abs(np.diff(angles))
        noise_mask = angle_diffs > self.confidence_params['max_angle_change']
        
        if np.any(noise_mask):
            window = self.confidence_params['noise_window']
            angles = np.convolve(angles, np.ones(window)/window, mode='same')
        
        return angles

    def _detect_gait_cycles(self, knee_angles):
        """æ­©è¡Œå‘¨æœŸæ¤œå‡ºï¼ˆå¼·åŒ–ã•ã‚ŒãŸå¹³æ»‘åŒ–ï¼‰"""
        if len(knee_angles) < 30:
            return None
        
        # å‹•çš„ã«çª“å¹…ã‚’èª¿æ•´
        optimal_window = int(len(knee_angles) * 0.12)
        if optimal_window % 2 == 0:
            optimal_window += 1
        window_length = min(max(optimal_window, 9), 21)
        
        # Savitzky-Golayãƒ•ã‚£ãƒ«ã‚¿ï¼ˆå¼·åŒ–ç‰ˆï¼‰
        if window_length >= 5:
            smoothed = signal.savgol_filter(knee_angles, window_length, 2)
        else:
            smoothed = knee_angles
        
        # ç§»å‹•å¹³å‡ã§è¿½åŠ å¹³æ»‘åŒ–
        smoothed = np.convolve(smoothed, np.ones(3)/3, mode='same')
        
        # ãƒ”ãƒ¼ã‚¯æ¤œå‡º
        peaks, properties = signal.find_peaks(
            smoothed,
            distance=self.gait_cycle_params['min_peak_distance'],
            prominence=self.gait_cycle_params['prominence']
        )
        
        # è°·æ¤œå‡º
        troughs, _ = signal.find_peaks(
            -smoothed,
            distance=self.gait_cycle_params['min_peak_distance'],
            prominence=self.gait_cycle_params['prominence']
        )
        
        if len(peaks) == 0:
            return None
        
        # æ­©è¡Œå‘¨æœŸã®å®šç¾©
        cycles = []
        for i in range(len(peaks) - 1):
            start_idx = peaks[i]
            end_idx = peaks[i + 1]
            
            cycle_length = end_idx - start_idx
            stance_start = max(0, start_idx - int(cycle_length * 0.2))
            stance_end = min(len(smoothed), start_idx + int(cycle_length * 0.2))
            
            cycles.append({
                'start': start_idx,
                'end': end_idx,
                'peak': start_idx,
                'stance_phase': (stance_start, stance_end),
                'peak_angle': smoothed[start_idx]
            })
        
        return {
            'cycles': cycles,
            'smoothed_angles': smoothed,
            'raw_angles': knee_angles,
            'peaks': peaks,
            'troughs': troughs
        }

    def _calculate_stance_phase_metrics(self, gait_data):
        """ç«‹è„šæœŸã®å¹³å‡çš„ãªè†ä¼¸å±•è§’åº¦ã‚’è©•ä¾¡"""
        if not gait_data or not gait_data['cycles']:
            return None
        
        stance_means = []
        stance_maxs = []
        
        for cycle in gait_data['cycles']:
            stance_start, stance_end = cycle['stance_phase']
            stance_angles = gait_data['smoothed_angles'][stance_start:stance_end]
            
            if len(stance_angles) > 0:
                stance_means.append(np.mean(stance_angles))
                stance_maxs.append(np.max(stance_angles))
        
        return {
            'mean_stance_extension': np.mean(stance_means) if stance_means else 0,
            'mean_peak_extension': np.mean(stance_maxs) if stance_maxs else 0,
            'consistency': np.std(stance_means) if len(stance_means) > 1 else 0,
            'num_cycles': len(gait_data['cycles'])
        }

    def _calculate_trunk_alignment(self, landmarks_history):
        """ä½“å¹¹ã®å‚ç›´æ€§ã‚’è©•ä¾¡"""
        trunk_angles = []
        visibilities = []
        
        for lm in landmarks_history:
            try:
                shoulder = np.array([lm[12].x, lm[12].y])
                hip = np.array([lm[24].x, lm[24].y])
                
                shoulder_vis = lm[12].visibility
                hip_vis = lm[24].visibility
                avg_vis = (shoulder_vis + hip_vis) / 2
                
                if avg_vis < 0.5:
                    continue
                
                trunk_vector = hip - shoulder
                vertical_vector = np.array([0, 1])
                
                dot_product = np.dot(trunk_vector, vertical_vector)
                trunk_norm = np.linalg.norm(trunk_vector)
                vertical_norm = np.linalg.norm(vertical_vector)
                
                cos_angle = dot_product / (trunk_norm * vertical_norm)
                angle_rad = np.arccos(np.clip(cos_angle, -1.0, 1.0))
                trunk_angle = np.degrees(angle_rad)
                
                trunk_angles.append(np.abs(trunk_angle))
                visibilities.append(avg_vis)
                
            except:
                continue
        
        if not trunk_angles:
            return None
        
        filtered_trunk_angles = self._filter_by_confidence(trunk_angles, visibilities)
        
        return {
            'mean_trunk_angle': np.mean(filtered_trunk_angles),
            'max_trunk_angle': np.max(filtered_trunk_angles),
            'trunk_variability': np.std(filtered_trunk_angles),
            'trunk_angles_series': filtered_trunk_angles.tolist()
        }

    def _interpret_consistency(self, consistency_sd):
        """ä¸€è²«æ€§ï¼ˆSDï¼‰ã®ç†å­¦ç™‚æ³•å£«çš„è§£é‡ˆ"""
        if consistency_sd < self.thresholds['consistency_excellent']:
            return {
                'level': 'excellent',
                'label': 'å„ªç§€ï¼ˆãƒªã‚ºãƒ ãŒéå¸¸ã«å®‰å®šï¼‰',
                'color': 'success',
                'icon': 'ğŸŒŸ',
                'explanation': 'å„æ­©è¡Œå‘¨æœŸã§æ¥µã‚ã¦å®‰å®šã—ãŸè†ã®å‹•ããŒã§ãã¦ã„ã¾ã™ã€‚ç¥çµŒç­‹å”èª¿æ€§ãŒå„ªã‚Œã¦ã„ã‚‹è¨¼æ‹ ã§ã™ã€‚',
                'advice': 'ã“ã®çŠ¶æ…‹ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚å®šæœŸçš„ãªæ­©è¡Œãƒã‚§ãƒƒã‚¯ã§çµŒéè¦³å¯Ÿã‚’ã€‚'
            }
        elif consistency_sd < self.thresholds['consistency_good']:
            return {
                'level': 'good',
                'label': 'è‰¯å¥½ï¼ˆãƒªã‚ºãƒ ãŒå®‰å®šï¼‰',
                'color': 'success',
                'icon': 'âœ…',
                'explanation': 'æ­©è¡Œãƒªã‚ºãƒ ã¯å®‰å®šã—ã¦ã„ã¾ã™ã€‚ã‚ãšã‹ãªã°ã‚‰ã¤ãã¯æ­£å¸¸ç¯„å›²å†…ã§ã™ã€‚',
                'advice': 'ç¾åœ¨ã®çŠ¶æ…‹ã‚’ç¶­æŒã—ãªãŒã‚‰ã€è‚¡é–¢ç¯€ãƒ»è¶³é–¢ç¯€ã®æŸ”è»Ÿæ€§ã‚’ä¿ã¡ã¾ã—ã‚‡ã†ã€‚'
            }
        elif consistency_sd < self.thresholds['consistency_moderate']:
            return {
                'level': 'moderate',
                'label': 'ä¸­ç¨‹åº¦ï¼ˆè»½åº¦ã®ã°ã‚‰ã¤ãï¼‰',
                'color': 'warning',
                'icon': 'âš ï¸',
                'explanation': 'æ­©è¡Œå‘¨æœŸã”ã¨ã«è†ã®ä¼¸ã³æ–¹ã«è»½åº¦ã®ã°ã‚‰ã¤ããŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚ç–²åŠ´ã‚„é›†ä¸­åŠ›ã®ä½ä¸‹ãŒå½±éŸ¿ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚',
                'advice': 'å·¦å³ã®ç­‹åŠ›ãƒãƒ©ãƒ³ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€ç–²ã‚ŒãŸæ™‚ã®æ­©ãæ–¹ã«æ³¨æ„ã‚’æ‰•ã„ã¾ã—ã‚‡ã†ã€‚'
            }
        elif consistency_sd < self.thresholds['consistency_poor']:
            return {
                'level': 'poor',
                'label': 'ä¸å®‰å®šï¼ˆã°ã‚‰ã¤ãã‚ã‚Šï¼‰',
                'color': 'warning',
                'icon': 'âš ï¸',
                'explanation': f'æ­©è¡Œãƒªã‚ºãƒ ã«ä¸å®‰å®šã•ãŒè¦‹ã‚‰ã‚Œã¾ã™ï¼ˆæ¨™æº–åå·®: {round(consistency_sd, 1)}åº¦ï¼‰ã€‚ç‰‡å´ã®ç­‹åŠ›ä½ä¸‹ã‚„é–¢ç¯€å¯å‹•åŸŸåˆ¶é™ãŒåŸå› ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚',
                'advice': 'é¡ã®å‰ã§æ­©è¡Œã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å·¦å³å·®ãŒãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚ç¶™ç¶šã™ã‚‹å ´åˆã¯ç†å­¦ç™‚æ³•å£«ã®è©•ä¾¡ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚'
            }
        else:
            return {
                'level': 'very_poor',
                'label': 'éå¸¸ã«ä¸å®‰å®šï¼ˆHigh Riskï¼‰',
                'color': 'danger',
                'icon': 'ğŸš¨',
                'explanation': f'æ­©è¡Œãƒªã‚ºãƒ ãŒéå¸¸ã«ä¸å®‰å®šã§ã™ï¼ˆæ¨™æº–åå·®: {round(consistency_sd, 1)}åº¦ï¼‰ã€‚ã“ã‚Œã¯ç—›ã¿ã®å›é¿ã€ç­‹åŠ›ä½ä¸‹ã€ã¾ãŸã¯ç¥çµŒç³»ã®å”èª¿æ€§ä½ä¸‹ã«ã‚ˆã‚‹ä»£å„Ÿå‹•ä½œã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚',
                'advice': '**å°‚é–€å®¶ã¸ã®ç›¸è«‡ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚** ç†å­¦ç™‚æ³•å£«ã¾ãŸã¯æ•´å½¢å¤–ç§‘åŒ»ã®è©•ä¾¡ã‚’å—ã‘ã€æ ¹æœ¬åŸå› ã‚’ç‰¹å®šã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚'
            }

    def _generate_clinical_recommendations(self, knee_metrics, trunk_metrics, gait_data):
        """ç†å­¦ç™‚æ³•å£«è¦–ç‚¹ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆï¼ˆå¼·åŒ–ç‰ˆï¼‰"""
        recs = []
        risk_level = "low"
        
        mean_stance = knee_metrics['mean_stance_extension']
        mean_peak = knee_metrics['mean_peak_extension']
        consistency = knee_metrics['consistency']
        
        consistency_interp = self._interpret_consistency(consistency)
        
        recs.append("### ğŸš¶â€â™€ï¸ ã‚ãªãŸã®æ­©è¡Œãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")
        
        # è†ã®è©•ä¾¡
        if mean_stance < self.thresholds['stance_phase_mean_minimum']:
            risk_level = "high"
            recs.append(f"**è†ã®ä¼¸ã³ã«é–¢ã™ã‚‹å¤§åˆ‡ãªãŠçŸ¥ã‚‰ã›**  ")
            recs.append(f"ç«‹è„šæœŸã®å¹³å‡è†ä¼¸å±•ã¯{round(mean_stance, 1)}åº¦ã§ã™ã€‚")
            recs.append("")
            recs.append("ğŸ’­ **ç†å­¦ç™‚æ³•å£«ã‹ã‚‰ã®æ°—ã¥ã**  ")
            recs.append("è†ãŒå®Œå…¨ã«ä¼¸ã³ãã‚‰ãªã„æ­©ãæ–¹ã¯ã€å®Ÿã¯å¤šãã®åƒãå¥³æ€§ã«è¦‹ã‚‰ã‚Œã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚ãƒ‡ã‚¹ã‚¯ãƒ¯ãƒ¼ã‚¯ã§è‚¡é–¢ç¯€å±ˆç­‹ç¾¤ãŒç¡¬ããªã£ãŸã‚Šã€ãƒ’ãƒ¼ãƒ«ã‚’å±¥ãç¿’æ…£ã§ä»£å„Ÿå‹•ä½œãŒèµ·ããŸã‚Šã™ã‚‹ã“ã¨ã§ã€ç„¡æ„è­˜ã«è†ã‚’è»½ãæ›²ã’ã¦æ­©ãã‚¯ã‚»ãŒã¤ã„ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚")
            recs.append("")
            recs.append("ğŸŒ¸ **å¥³æ€§ã®èº«ä½“ã‚’å®ˆã‚‹è¦–ç‚¹**  ")
            recs.append("- **éª¨ç›¤åº•ç­‹ã¸ã®å½±éŸ¿**: è†ãŒä¼¸ã³ãªã„ã¨ä½“å¹¹ãŒå‰å‚¾ã—ã€éª¨ç›¤åº•ç­‹ã«ä½™è¨ˆãªè² æ‹…ãŒã‹ã‹ã‚Šã¾ã™")
            recs.append("- **å°†æ¥ã®è†ç—›ãƒªã‚¹ã‚¯**: 40ä»£ä»¥é™ã€å¥³æ€§ã¯ç”·æ€§ã®2å€ã®ç¢ºç‡ã§å¤‰å½¢æ€§è†é–¢ç¯€ç—‡ã‚’ç™ºç—‡ã—ã¾ã™")
            recs.append("- **ç–²åŠ´ã®è“„ç©**: å¤•æ–¹ã«ãªã‚‹ã¨è¶³ãŒé‡ãæ„Ÿã˜ã‚‹ã®ã¯ã€ã“ã®æ­©ãæ–¹ãŒåŸå› ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“")
            recs.append("")
            recs.append("ğŸ’¡ **ä»Šæ—¥ã‹ã‚‰å§‹ã‚ã‚‹3ã¤ã®ã‚±ã‚¢**  ")
            recs.append("1. **ãƒ‡ã‚¹ã‚¯ã§ã§ãã‚‹è‚¡é–¢ç¯€ã‚¹ãƒˆãƒ¬ãƒƒãƒ**: æ¤…å­ã«æµ…ãåº§ã‚Šã€ç‰‡è¶³ã‚’å‰ã«ä¼¸ã°ã—ã¦è†è£ã‚’åºŠã«è¿‘ã¥ã‘ã‚‹ï¼ˆ15ç§’Ã—3å›ï¼‰")
            recs.append("2. **æ­©è¡Œã®æ„è­˜æ”¹é©**: ã€Œã‹ã‹ã¨â†’å°æŒ‡çƒâ†’è¦ªæŒ‡çƒã€ã®é †ã§åœ°é¢ã‚’æŠ¼ã™æ„Ÿè¦šã‚’æ„è­˜")
            recs.append("3. **éª¨ç›¤åº•ç­‹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°**: ç«‹è„šæœŸã«éª¨ç›¤åº•ã‚’è»½ãå¼•ãä¸Šã’ã‚‹æ„è­˜ã‚’æŒã¤")
            
        elif mean_stance < self.thresholds['knee_extension_good']:
            risk_level = "moderate"
            recs.append(f"**è†ã®ä¼¸ã³ã¯æ¦‚ã­è‰¯å¥½ã§ã™**  ")
            recs.append(f"ç«‹è„šæœŸã®å¹³å‡è†ä¼¸å±•ã¯{round(mean_stance, 1)}åº¦ï¼ˆè‰¯å¥½åŸºæº–: {self.thresholds['knee_extension_good']}åº¦ä»¥ä¸Šï¼‰")
            recs.append("")
            recs.append("âœ¨ **ã‚ã¨ä¸€æ­©ã§ç†æƒ³çš„ãªæ­©è¡Œã¸**  ")
            recs.append("ç¾åœ¨ã®æ­©ãæ–¹ã¯è‰¯ã„çŠ¶æ…‹ã§ã™ã€‚ã‚ã¨å°‘ã—è†ã®ä¼¸ã³ã‚’æ”¹å–„ã™ã‚‹ã“ã¨ã§ã€ä»¥ä¸‹ã®ãƒ¡ãƒªãƒƒãƒˆãŒå¾—ã‚‰ã‚Œã¾ã™ï¼š")
            recs.append("- é•·æ™‚é–“æ­©ã„ã¦ã‚‚ç–²ã‚Œã«ãã„èº«ä½“")
            recs.append("- å¤•æ–¹ã®ä¸‹åŠèº«ã®ã‚€ãã¿è»½æ¸›")
            recs.append("- éª¨ç›¤åº•ç­‹ã®æ©Ÿèƒ½ç¶­æŒ")
            recs.append("")
            recs.append("ğŸ¯ **ãƒ¯ãƒ³ãƒ©ãƒ³ã‚¯ä¸Šã®æ­©è¡Œã¸**  ")
            recs.append("é€šå‹¤æ™‚ã«ã€Œèƒ¸ã‚’é–‹ã„ã¦ã€é ãã‚’è¦‹ã¦æ­©ãã€ã“ã¨ã‚’æ„è­˜ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
            
        elif mean_stance < self.thresholds['knee_extension_ideal']:
            risk_level = "low"
            recs.append(f"**è†ã®ä¼¸ã³ã¯è‰¯å¥½ã§ã™ï¼**  ")
            recs.append(f"ç«‹è„šæœŸã®å¹³å‡è†ä¼¸å±•ã¯{round(mean_stance, 1)}åº¦ã€‚ã¨ã¦ã‚‚è‰¯ã„çŠ¶æ…‹ã§ã™ã€‚")
            recs.append(f"ç†æƒ³å€¤ã®{self.thresholds['knee_extension_ideal']}åº¦ã¾ã§ã‚ã¨{round(self.thresholds['knee_extension_ideal'] - mean_stance, 1)}åº¦ã§ã™ã€‚")
            
        else:
            recs.append(f"**âœ¨ ç†æƒ³çš„ãªè†ã®ä¼¸ã³ã§ã™ï¼**  ")
            recs.append(f"ç«‹è„šæœŸã®å¹³å‡è†ä¼¸å±•ã¯{round(mean_stance, 1)}åº¦ã€‚ç´ æ™´ã‚‰ã—ã„æ­©è¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚")
            recs.append("")
            recs.append("ğŸŒŸ **ã“ã®æ­©ãæ–¹ãŒã‚‚ãŸã‚‰ã™æ©æµ**  ")
            recs.append("- **éª¨ç›¤åº•ç­‹ã®æ©Ÿèƒ½ç¶­æŒ**: ä½“å¹¹ãŒå®‰å®šã—ã€éª¨ç›¤åº•ç­‹ã¸ã®è² æ‹…ãŒæœ€å°é™")
            recs.append("- **è†é–¢ç¯€ã®å¥åº·**: å°†æ¥ã®å¤‰å½¢æ€§è†é–¢ç¯€ç—‡ãƒªã‚¹ã‚¯ãŒä½ã„æ­©è¡Œãƒ‘ã‚¿ãƒ¼ãƒ³")
            recs.append("- **ç”Ÿç”£æ€§å‘ä¸Š**: ç–²ã‚Œã«ãã„èº«ä½“ã§ã€åˆå¾Œã®é›†ä¸­åŠ›ã‚‚ç¶­æŒ")
        
        # ä¸€è²«æ€§ã®è©³ç´°è©•ä¾¡
        recs.append("")
        recs.append(f"{consistency_interp['icon']} **æ­©è¡Œãƒªã‚ºãƒ ã®å®‰å®šåº¦: {consistency_interp['label']}**  ")
        recs.append(consistency_interp['explanation'])
        recs.append(f"**ã‚¢ãƒ‰ãƒã‚¤ã‚¹**: {consistency_interp['advice']}")
        
        # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã‚’ä¸€è²«æ€§ã‹ã‚‰ã‚‚åˆ¤å®š
        if consistency_interp['level'] == 'very_poor':
            risk_level = 'critical'
        elif consistency_interp['level'] == 'poor' and risk_level == 'low':
            risk_level = 'moderate'
        
        # ä½“å¹¹ã®è©•ä¾¡
        if trunk_metrics:
            recs.append("")
            recs.append("### ğŸ§˜â€â™€ï¸ ä½“å¹¹ã®è©•ä¾¡ï¼ˆSakane 2025ãƒ¢ãƒ‡ãƒ«ï¼‰")
            mean_trunk = trunk_metrics['mean_trunk_angle']
            
            if mean_trunk > self.thresholds['trunk_risk_threshold']:
                risk_level = "high" if risk_level not in ['critical', 'high'] else risk_level
                recs.append(f"**ä½“å¹¹ã®å‚¾ããŒæ°—ã«ãªã‚Šã¾ã™**  ")
                recs.append(f"å¹³å‡ä½“å¹¹å‚¾æ–œ: {round(mean_trunk, 1)}åº¦ï¼ˆç†æƒ³å€¤: {self.thresholds['trunk_alignment_ideal']}åº¦ä»¥å†…ï¼‰")
                recs.append("")
                recs.append("ğŸ¯ **ä½“å¹¹å‚¾æ–œã¨å¥³æ€§ã®å¥åº·**  ")
                recs.append("ä½“å¹¹ãŒå‰å‚¾ã™ã‚‹ã¨ã€éª¨ç›¤åº•ç­‹ã«æŒç¶šçš„ãªä¸‹å‘ãã®åœ§åŠ›ãŒã‹ã‹ã‚Šã€å°†æ¥çš„ãªå°¿ã‚‚ã‚Œã‚„éª¨ç›¤è‡“å™¨è„±ã®ãƒªã‚¹ã‚¯ãŒé«˜ã¾ã‚Šã¾ã™ã€‚")
                recs.append("")
                recs.append("ğŸ’¡ **ä½“å¹¹ã‚’æ•´ãˆã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**  ")
                recs.append("1. **å‘¼å¸ã¨ä½“å¹¹ã®é€£å‹•**: é¼»ã‹ã‚‰å¸ã£ã¦ã€æ¯ã‚’åãã¨ãã«éª¨ç›¤åº•ã‚’å¼•ãä¸Šã’ã‚‹")
                recs.append("2. **ãƒ—ãƒ©ãƒ³ã‚¯å¤‰æ³•**: è†ã‚’ã¤ã„ãŸçŠ¶æ…‹ã§10ç§’ã‚­ãƒ¼ãƒ—")
                recs.append("3. **æ­©è¡Œæ™‚ã®æ„è­˜**: ã€Œé ­ãŒå¤©äº•ã‹ã‚‰ç³¸ã§å¼•ã£å¼µã‚‰ã‚Œã¦ã„ã‚‹ã€ã‚¤ãƒ¡ãƒ¼ã‚¸ã§")
                
            elif mean_trunk > self.thresholds['trunk_alignment_ideal']:
                recs.append(f"**ä½“å¹¹ã¯ã»ã¼è‰¯å¥½ã§ã™**  ")
                recs.append(f"å¹³å‡ä½“å¹¹å‚¾æ–œ: {round(mean_trunk, 1)}åº¦")
                recs.append("ãƒ‡ã‚¹ã‚¯ãƒ¯ãƒ¼ã‚¯ã®å§¿å‹¢ãŒå½±éŸ¿ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                
            else:
                recs.append(f"**âœ¨ ç†æƒ³çš„ãªä½“å¹¹ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã§ã™ï¼**  ")
                recs.append(f"å¹³å‡ä½“å¹¹å‚¾æ–œ: {round(mean_trunk, 1)}åº¦")
        
        # ç·åˆãƒªã‚¹ã‚¯è©•ä¾¡
        recs.append("")
        recs.append("---")
        if risk_level == "critical":
            recs.append("### ğŸš¨ ç·åˆè©•ä¾¡: è¦å°‚é–€å®¶ç›¸è«‡ï¼ˆCritical Riskï¼‰")
            recs.append("ç¾åœ¨ã®æ­©è¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã¯é‡å¤§ãªä¸å®‰å®šæ€§ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚ç—›ã¿ã‚„æ©Ÿèƒ½éšœå®³ã®å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€**å¿…ãšç†å­¦ç™‚æ³•å£«ã¾ãŸã¯æ•´å½¢å¤–ç§‘åŒ»ã®è©•ä¾¡ã‚’å—ã‘ã¦ãã ã•ã„ã€‚**")
        elif risk_level == "high":
            recs.append("### ğŸ”” ç·åˆè©•ä¾¡: æ”¹å–„æ¨å¥¨ï¼ˆHigh Riskï¼‰")
            recs.append("ç¾åœ¨ã®æ­©è¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã¯æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™ã€‚ä¸Šè¨˜ã®ã‚±ã‚¢ã‚’2é€±é–“ç¶šã‘ã¦ã€å†åº¦æ¸¬å®šã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")
        elif risk_level == "moderate":
            recs.append("### ğŸ’š ç·åˆè©•ä¾¡: è‰¯å¥½ï¼ˆModerateï¼‰")
            recs.append("ç¾åœ¨ã®çŠ¶æ…‹ã¯è‰¯å¥½ã§ã™ã€‚ç¶™ç¶šçš„ãªã‚±ã‚¢ã§ç†æƒ³çš„ãªæ­©è¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰‹ã«å…¥ã‚Œã¾ã—ã‚‡ã†ã€‚")
        else:
            recs.append("### ğŸŒŸ ç·åˆè©•ä¾¡: å„ªè‰¯ï¼ˆExcellentï¼‰")
            recs.append("ç´ æ™´ã‚‰ã—ã„æ­©è¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚ã“ã®çŠ¶æ…‹ã‚’ç¶­æŒã™ã‚‹ã“ã¨ã§ã€ç”Ÿæ¶¯ã«ã‚ãŸã‚‹èº«ä½“ã®å¥åº·ãŒæœŸå¾…ã§ãã¾ã™ã€‚")
        
        return recs, risk_level, consistency_interp

    def analyze_clinical_data(self, landmarks_history):
        """è‡¨åºŠãƒ‡ãƒ¼ã‚¿ã®ç·åˆåˆ†æ"""
        if not landmarks_history or len(landmarks_history) < 30:
            return {
                'error': 'ãƒ‡ãƒ¼ã‚¿ä¸è¶³',
                'message': 'æ­©è¡Œåˆ†æã«ã¯æœ€ä½1ç§’é–“ï¼ˆç´„30ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰ã®å‹•ç”»ãŒå¿…è¦ã§ã™ã€‚'
            }
        
        knee_angles = []
        knee_visibilities = []
        
        for lm in landmarks_history:
            try:
                hip = [lm[24].x, lm[24].y]
                knee = [lm[26].x, lm[26].y]
                ankle = [lm[28].x, lm[28].y]
                
                hip_vis = lm[24].visibility
                knee_vis = lm[26].visibility
                ankle_vis = lm[28].visibility
                avg_vis = (hip_vis + knee_vis + ankle_vis) / 3
                
                if avg_vis < 0.5:
                    continue
                    
                angle = self._calculate_angle(hip, knee, ankle)
                knee_angles.append(angle)
                knee_visibilities.append(avg_vis)
            except:
                continue
        
        if len(knee_angles) < 30:
            return {
                'error': 'ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡ºä¸è¶³',
                'message': 'è†ãƒ»è‚¡é–¢ç¯€ãƒ»è¶³é¦–ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãŒååˆ†ã«æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚'
            }
        
        filtered_knee_angles = self._filter_by_confidence(knee_angles, knee_visibilities)
        gait_data = self._detect_gait_cycles(filtered_knee_angles)
        
        if not gait_data or len(gait_data['cycles']) == 0:
            max_extension = max(filtered_knee_angles)
            return {
                'max_knee_angle': round(max_extension, 1),
                'analysis_type': 'simple',
                'recommendations': [
                    "âš ï¸ æ­©è¡Œå‘¨æœŸãŒæ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚",
                    "ã‚ˆã‚Šé•·ã„è·é›¢ã‚’ãƒªãƒ©ãƒƒã‚¯ã‚¹ã—ã¦æ­©ã„ã¦ã„ã‚‹å‹•ç”»ã§å†æ¸¬å®šã—ã¦ãã ã•ã„ã€‚",
                    f"å‚è€ƒå€¤: æœ€å¤§è†ä¼¸å±•è§’åº¦ {round(max_extension, 1)}åº¦"
                ],
                'metrics': {'knee_flexion': round(max_extension, 1)}
            }
        
        knee_metrics = self._calculate_stance_phase_metrics(gait_data)
        trunk_metrics = self._calculate_trunk_alignment(landmarks_history)
        recommendations, risk_level, consistency_interp = self._generate_clinical_recommendations(
            knee_metrics, trunk_metrics, gait_data
        )
        
        return {
            'analysis_type': 'advanced',
            'gait_cycles_detected': len(gait_data['cycles']),
            'knee_metrics': {
                'mean_stance_extension': round(knee_metrics['mean_stance_extension'], 1),
                'mean_peak_extension': round(knee_metrics['mean_peak_extension'], 1),
                'consistency': round(knee_metrics['consistency'], 1),
                'consistency_interpretation': consistency_interp,
                'max_knee_angle': round(knee_metrics['mean_peak_extension'], 1)
            },
            'trunk_metrics': {
                'mean_trunk_angle': round(trunk_metrics['mean_trunk_angle'], 1) if trunk_metrics else None,
                'trunk_variability': round(trunk_metrics['trunk_variability'], 1) if trunk_metrics else None
            } if trunk_metrics else None,
            'risk_level': risk_level,
            'recommendations': recommendations,
            'raw_data': {
                'knee_angles_series': filtered_knee_angles.tolist(),
                'smoothed_angles': gait_data['smoothed_angles'].tolist(),
                'peaks': gait_data['peaks'].tolist(),
                'troughs': gait_data['troughs'].tolist()
            }
        }

    def export_for_sakane_model(self, analysis_result):
        """Sakane 2025ãƒ¢ãƒ‡ãƒ«ç”¨ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        if analysis_result.get('analysis_type') != 'advanced':
            return None
        
        return {
            'variable_1_knee_extension': analysis_result['knee_metrics']['mean_stance_extension'],
            'variable_2_trunk_alignment': analysis_result['trunk_metrics']['mean_trunk_angle'] if analysis_result['trunk_metrics'] else None,
            'variable_3_gait_consistency': analysis_result['knee_metrics']['consistency'],
            'variable_4_step_length': None,
            'variable_5_cadence': None,
            'analysis_timestamp': np.datetime64('now'),
            'model_version': 'Sakane2025_v1.2_advanced'
        }
