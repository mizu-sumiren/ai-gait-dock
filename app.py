import streamlit as st
import cv2
import numpy as np
import tempfile
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# MediaPipeã®å …ç‰¢ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import mediapipe as mp
    mp_pose = mp.solutions.pose
    mp_drawing = mp.solutions.drawing_utils
    mp_drawing_styles = mp.solutions.drawing_styles
    MEDIAPIPE_AVAILABLE = True
except (ImportError, AttributeError) as e:
    st.error(f"MediaPipeã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    MEDIAPIPE_AVAILABLE = False

from female_gait_analyzer import FemaleGaitAnalyzer

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="AIæ­©è¡Œãƒ‰ãƒƒã‚¯ ãƒ•ã‚§ãƒ¼ã‚º3",
    page_icon="ğŸšº",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSSï¼ˆæ¸©ã‹ã¿ã®ã‚ã‚‹ãƒ‡ã‚¶ã‚¤ãƒ³ï¼‰
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #E91E63;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #757575;
        text-align: center;
        margin-bottom: 2rem;
    }
    .recommendation-card {
        background-color: #FFF3E0;
        border-left: 5px solid #FF9800;
        padding: 1.5rem;
        border-radius: 8px;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .success-card {
        background-color: #E8F5E9;
        border-left: 5px solid #4CAF50;
        padding: 1.5rem;
        border-radius: 8px;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .warning-card {
        background-color: #FFF3E0;
        border-left: 5px solid #FFC107;
        padding: 1.5rem;
        border-radius: 8px;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .danger-card {
        background-color: #FFEBEE;
        border-left: 5px solid #F44336;
        padding: 1.5rem;
        border-radius: 8px;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .metric-container {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 12px;
        color: white;
        text-align: center;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .stProgress > div > div > div > div {
        background-color: #4CAF50;
    }
</style>
""", unsafe_allow_html=True)

# ãƒ˜ãƒƒãƒ€ãƒ¼
st.markdown('<p class="main-header">ğŸšº AIæ­©è¡Œãƒ‰ãƒƒã‚¯ï¼šãƒ•ã‚§ãƒ¼ã‚º3</p>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">ç†å­¦ç™‚æ³•å£«ã®è¦–ç‚¹ã‚’çµ„ã¿è¾¼ã‚“ã ã€ã‚ãªãŸã®ãŸã‚ã®æ­©è¡Œåˆ†æ</p>', unsafe_allow_html=True)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.markdown("### ğŸ©º AIæ­©è¡Œãƒ‰ãƒƒã‚¯ã¨ã¯")
    st.write("""
    ç†å­¦ç™‚æ³•å£«ã®è‡¨åºŠçŸ¥è­˜ã¨AIæŠ€è¡“ã‚’èåˆã•ã›ãŸã€
    åƒãå¥³æ€§ã®ãŸã‚ã®æ­©è¡Œåˆ†æã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚
    
    **ç‰¹å¾´:**
    - æ­©è¡Œå‘¨æœŸã®è‡ªå‹•æ¤œå‡º
    - ç«‹è„šæœŸã®è©³ç´°åˆ†æ
    - ä½“å¹¹ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆè©•ä¾¡
    - éª¨ç›¤åº•ç­‹ãƒªã‚¹ã‚¯è©•ä¾¡
    """)
    
    st.markdown("---")
    st.markdown("### ğŸ“‹ ä½¿ã„æ–¹")
    st.write("""
    1. æ¨ªã‹ã‚‰æ’®å½±ã—ãŸæ­©è¡Œå‹•ç”»ã‚’ç”¨æ„
    2. å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    3. AIãŒè‡ªå‹•è§£æ
    4. ç†å­¦ç™‚æ³•å£«ã‹ã‚‰ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ç¢ºèª
    """)
    
    st.markdown("---")
    st.caption("Developed by ã™ã¿ã‚Œã‚“ | ç†å­¦ç™‚æ³•å£« Ã— AI")

# MediaPipeåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
if not MEDIAPIPE_AVAILABLE:
    st.error("âš ï¸ MediaPipeãŒæ­£ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚pip install mediapipe ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼
st.markdown("### ğŸ“¹ æ­©è¡Œå‹•ç”»ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
uploaded_file = st.file_uploader(
    "æ¨ªã‹ã‚‰æ’®å½±ã—ãŸæ­©è¡Œå‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆ2-5æ­©ç¨‹åº¦ã®è‡ªç„¶ãªæ­©è¡Œï¼‰",
    type=['mp4', 'mov', 'avi'],
    help="ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã§æ¨ªå‘ãã«æ’®å½±ã—ãŸå‹•ç”»ãŒæœ€é©ã§ã™"
)

if uploaded_file is not None:
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tfile:
        tfile.write(uploaded_file.read())
        temp_video_path = tfile.name
    
    try:
        # ãƒ“ãƒ‡ã‚ªã‚­ãƒ£ãƒ—ãƒãƒ£ã®åˆæœŸåŒ–
        cap = cv2.VideoCapture(temp_video_path)
        
        # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ãé–‹ã‘ãŸã‹ç¢ºèª
        if not cap.isOpened():
            st.error("âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        
        if total_frames == 0:
            st.error("âŒ å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒ0ã§ã™ã€‚æœ‰åŠ¹ãªå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            cap.release()
            st.stop()
        
        # MediaPipe Poseã®åˆæœŸåŒ–
        with mp_pose.Pose(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5,
            model_complexity=1
        ) as pose:
            
            landmarks_history = []
            frame_count = 0
            
            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
            col1, col2 = st.columns([2, 1])
            with col1:
                st_frame = st.empty()
            with col2:
                st.markdown("#### ğŸ“Š ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†")
                frame_info = st.empty()
                landmark_info = st.empty()
            
            status_text.info("ğŸ” å‹•ç”»ã‚’è§£æä¸­... éª¨æ ¼ã‚’æ¤œå‡ºã—ã¦ã„ã¾ã™")
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†è¨­å®š
            DISPLAY_INTERVAL = 10  # 10ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«è¡¨ç¤ºæ›´æ–°ï¼ˆå‡¦ç†è»½æ¸›ï¼‰
            PREVIEW_WIDTH = 640    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºã®å¹…ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰
            
            while cap.isOpened():
                ret, frame = cap.read()
                
                # === 1. ãƒ•ãƒ¬ãƒ¼ãƒ å­˜åœ¨ãƒã‚§ãƒƒã‚¯ï¼ˆäºŒé‡ç¢ºèªï¼‰ ===
                if not ret or frame is None:
                    # å‹•ç”»çµ‚ç«¯ã¾ãŸã¯èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼
                    break
                
                # === 2. ãƒ•ãƒ¬ãƒ¼ãƒ ã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯ ===
                if frame.size == 0:
                    # ç©ºã®ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆç¨€ã«ç™ºç”Ÿï¼‰
                    continue
                
                frame_count += 1
                progress = frame_count / total_frames if total_frames > 0 else 0
                progress_bar.progress(min(progress, 1.0))
                
                try:
                    # === 3. å®‰å…¨ãªRGBå¤‰æ› ===
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    
                    # MediaPipeå‡¦ç†
                    results = pose.process(frame_rgb)
                    
                    if results.pose_landmarks:
                        landmarks_history.append(results.pose_landmarks.landmark)
                        
                        # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æç”»
                        mp_drawing.draw_landmarks(
                            frame,
                            results.pose_landmarks,
                            mp_pose.POSE_CONNECTIONS,
                            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()
                        )
                        
                        landmark_info.success(f"âœ… éª¨æ ¼æ¤œå‡º: {len(landmarks_history)} ãƒ•ãƒ¬ãƒ¼ãƒ ")
                    else:
                        landmark_info.warning("âš ï¸ éª¨æ ¼æœªæ¤œå‡º")
                    
                    # ãƒ•ãƒ¬ãƒ¼ãƒ æƒ…å ±æ›´æ–°
                    frame_info.metric("å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ ", f"{frame_count}/{total_frames}")
                    
                    # === 4. åŠ¹ç‡çš„ãªãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º ===
                    if frame_count % DISPLAY_INTERVAL == 0:
                        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒªã‚µã‚¤ã‚ºã—ã¦è¡¨ç¤ºï¼ˆå‡¦ç†è»½æ¸›ï¼‰
                        height, width = frame.shape[:2]
                        if width > PREVIEW_WIDTH:
                            scale = PREVIEW_WIDTH / width
                            new_width = PREVIEW_WIDTH
                            new_height = int(height * scale)
                            frame_resized = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_AREA)
                        else:
                            frame_resized = frame
                        
                        # å®‰å…¨ãªç”»åƒè¡¨ç¤º
                        try:
                            st_frame.image(frame_resized, channels="BGR", use_container_width=True)
                        except Exception as img_error:
                            # ç”»åƒè¡¨ç¤ºã‚¨ãƒ©ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå‡¦ç†ã¯ç¶™ç¶šï¼‰
                            pass  # é™ã‹ã«ã‚¹ã‚­ãƒƒãƒ—
                
                except cv2.error as cv_error:
                    # OpenCVã‚¨ãƒ©ãƒ¼ï¼ˆç¨€ã«ç™ºç”Ÿï¼‰
                    continue  # ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã¸
                
                except Exception as e:
                    # ãã®ä»–ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼
                    continue  # ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã¸
            
            # === 5. ãƒ«ãƒ¼ãƒ—çµ‚äº†å¾Œã®å®‰å…¨ãªæœ€çµ‚è¡¨ç¤º ===
            try:
                if frame is not None and frame.size > 0:
                    # æœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤º
                    height, width = frame.shape[:2]
                    if width > PREVIEW_WIDTH:
                        scale = PREVIEW_WIDTH / width
                        new_width = PREVIEW_WIDTH
                        new_height = int(height * scale)
                        frame_resized = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_AREA)
                    else:
                        frame_resized = frame
                    
                    st_frame.image(frame_resized, channels="BGR", use_container_width=True)
            except:
                # æœ€çµ‚è¡¨ç¤ºã«å¤±æ•—ã—ã¦ã‚‚ç¶šè¡Œ
                pass
            
            cap.release()
            
            status_text.success(f"âœ… å‹•ç”»å‡¦ç†å®Œäº†: {len(landmarks_history)} ãƒ•ãƒ¬ãƒ¼ãƒ ã®éª¨æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")
            
            # --- ä»¥é™ã€åˆ†æå‡¦ç†ã¯å‰å›ã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ ---
            # ï¼ˆè‡¨åºŠåˆ†æã®å®Ÿè¡Œã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã“ã“ã«æŒ¿å…¥ï¼‰
            
            if len(landmarks_history) >= 30:
                st.markdown("---")
                status_text.info("ğŸ§  AIç†å­¦ç™‚æ³•å£«ãŒåˆ†æä¸­...")
                
                with st.spinner("è©³ç´°ãªæ­©è¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è§£æã—ã¦ã„ã¾ã™..."):
                    analyzer = FemaleGaitAnalyzer()
                    clinical_res = analyzer.analyze_clinical_data(landmarks_history)
                
                if clinical_res.get('error'):
                    st.error(f"âŒ {clinical_res['error']}: {clinical_res['message']}")
                else:
                    status_text.success("âœ¨ åˆ†æå®Œäº†ï¼ã‚ãªãŸã®æ­©è¡Œãƒ¬ãƒãƒ¼ãƒˆã‚’ã”è¦§ãã ã•ã„")
                    
                    # ä»¥é™ã€å‰å›æä¾›ã—ãŸUIã‚³ãƒ¼ãƒ‰ã‚’ãã®ã¾ã¾ä½¿ç”¨
                    # ï¼ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºã€ã‚°ãƒ©ãƒ•ã€ã‚¢ãƒ‰ãƒã‚¤ã‚¹ãªã©ï¼‰
                    
                    # === çµæœè¡¨ç¤ºã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå‰å›ã®ã‚³ãƒ¼ãƒ‰ã‚’ã“ã“ã«æŒ¿å…¥ï¼‰ ===
                    # ... (çœç•¥: å‰å›æä¾›ã—ãŸã‚³ãƒ¼ãƒ‰ã¨åŒã˜)
                    
            else:
                st.error(f"âŒ éª¨æ ¼ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {len(landmarks_history)}ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆæœ€ä½30ãƒ•ãƒ¬ãƒ¼ãƒ å¿…è¦ï¼‰")
                st.info("ğŸ’¡ æ”¹å–„æ¡ˆ: ã‚ˆã‚Šé•·ã„è·é›¢ã‚’æ­©ã„ã¦ã„ã‚‹å‹•ç”»ï¼ˆ3-5æ­©ä»¥ä¸Šï¼‰ã‚’æ’®å½±ã—ã¦ãã ã•ã„")
    
    except Exception as e:
        st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        import traceback
        st.code(traceback.format_exc())
    
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        import os
        try:
            if 'cap' in locals():
                cap.release()
            if os.path.exists(temp_video_path):
                os.unlink(temp_video_path)
        except:
            pass

else:
    # åˆæœŸç”»é¢ï¼šä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰
    st.markdown("---")
    st.markdown("## ğŸ“– AIæ­©è¡Œãƒ‰ãƒƒã‚¯ã®ä½¿ã„æ–¹")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        ### 1ï¸âƒ£ å‹•ç”»ã‚’æ’®å½±
        - æ¨ªã‹ã‚‰å…¨èº«ãŒæ˜ ã‚‹ã‚ˆã†ã«
        - 2-5æ­©ç¨‹åº¦æ­©ã
        - è‡ªç„¶ãªæ­©ãæ–¹ã§
        - æ˜ã‚‹ã„å ´æ‰€ã§æ’®å½±
        """)
    
    with col2:
        st.markdown("""
        ### 2ï¸âƒ£ å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        - ä¸Šã®ãƒœã‚¿ãƒ³ã‹ã‚‰é¸æŠ
        - mp4, mov, aviå¯¾å¿œ
        - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™ãªã—
        - iPhone/Androidä¸¡å¯¾å¿œ
        """)
    
    with col3:
        st.markdown("""
        ### 3ï¸âƒ£ çµæœã‚’ç¢ºèª
        - AIç†å­¦ç™‚æ³•å£«ãŒåˆ†æ
        - è©³ç´°ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹
        - ã‚°ãƒ©ãƒ•ã§å¯è¦–åŒ–
        - æ”¹å–„ãƒ—ãƒ©ãƒ³ã®ææ¡ˆ
        """)
    
    st.markdown("---")
    st.info("ğŸ’¡ ã¾ãšã¯ä¸Šã®ãƒœã‚¿ãƒ³ã‹ã‚‰æ­©è¡Œå‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #757575; padding: 2rem;'>
    <p><strong>AIæ­©è¡Œãƒ‰ãƒƒã‚¯ ãƒ•ã‚§ãƒ¼ã‚º3</strong></p>
    <p>Powered by MediaPipe Ã— ç†å­¦ç™‚æ³•å£«ã®è‡¨åºŠçŸ¥è­˜</p>
    <p>Developed by ã™ã¿ã‚Œã‚“ | Physical Therapist Ã— AI Engineer</p>
    <p style='font-size: 0.8rem; margin-top: 1rem;'>
        âš ï¸ æœ¬ã‚·ã‚¹ãƒ†ãƒ ã¯åŒ»ç™‚è¨ºæ–­ã‚’ç›®çš„ã¨ã—ãŸã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚<br>
        æ°—ã«ãªã‚‹ç—‡çŠ¶ãŒã‚ã‚‹å ´åˆã¯ã€åŒ»ç™‚æ©Ÿé–¢ã‚’å—è¨ºã—ã¦ãã ã•ã„ã€‚
    </p>
</div>
""", unsafe_allow_html=True)
